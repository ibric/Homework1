{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    " <p><div class=\"lev1\"><a href=\"#Task-A.-Another-LEGO-brick-in-the-wall\"><span class=\"toc-item-num\">Task A.&nbsp;&nbsp;</span>Another LEGO brick in the wall</a></div>\n",
    " <p><div class=\"lev1\"><a href=\"#Task-B.-Drop-the-Bike\"><span class=\"toc-item-num\">Task B.&nbsp;&nbsp;</span>Drop the Bike</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your imports here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A. Another LEGO brick in the wall\n",
    "\n",
    "LEGO is a popular brand of toy building bricks. They are often sold in sets in order to build a specific object. Each set contains a number of parts in different shapes, sizes and colors. This database contains information on which parts are included in different LEGO sets. It was originally compiled to help people who owned some LEGO sets already figure out what other sets they could build with the pieces they had.\n",
    "\n",
    "This dataset contains the official LEGO colors, parts, inventories (i.e., sets of LEGO parts which assembled create an object in the LEGO world) and sets (i.e., sets of LEGO inventories which assembled create a LEGO ecosystem). The schema of the dataset can be shown in the following UML diagram: \n",
    "\n",
    "![lego-schema](lego-schema.png)\n",
    "\n",
    "In this task you have to apply the following Data Wrangling pipeline:\n",
    "1. Load your data into `Pandas`\n",
    "* Explore it and clean its dirty parts\n",
    "* Use it to answer a set of queries\n",
    "\n",
    "Each of these subtasks are described in detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1. Loading phase\n",
    "Load all the csv files into different `DataFrames`. Use meaningful names for your `DataFrames` (e.g., the respective filenames).\n",
    "\n",
    "*Hint: You can load files without first unzipping them (for `Pandas` version >= 0.18.1).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEGO_DATA_FOLDER = DATA_FOLDER + '/lego'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "themes = pd.read_csv(LEGO_DATA_FOLDER + '/themes.csv.zip') #, dtype={''}\n",
    "colors = pd.read_csv(LEGO_DATA_FOLDER + '/colors.csv.zip')\n",
    "inventories = pd.read_csv(LEGO_DATA_FOLDER + '/inventories.csv.zip')\n",
    "inventory_parts = pd.read_csv(LEGO_DATA_FOLDER + '/inventory_parts.csv.zip')\n",
    "inventory_sets = pd.read_csv(LEGO_DATA_FOLDER + '/inventory_sets.csv.zip')\n",
    "part_categories = pd.read_csv(LEGO_DATA_FOLDER + '/part_categories.csv.zip')\n",
    "parts = pd.read_csv(LEGO_DATA_FOLDER + '/parts.csv.zip')\n",
    "sets = pd.read_csv(LEGO_DATA_FOLDER + '/sets.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2. Cleaning phase\n",
    "Explore the following columns from your dataset:\n",
    "\n",
    "1. sets: year\n",
    "* inventory_parts: quantity\n",
    "\n",
    "What is the time range of the sets? \n",
    "What is the average quantity of the inventory parts? \n",
    "Do you see any inconsistencies? \n",
    "Provide code that detects and cleans such inconsistencies and validates the coherence of your dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time range of the sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           70s\n",
      "7         19788\n",
      "11645    -20122\n",
      "11643     -2014\n",
      "Name: year, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sets.year.iloc[[0, 7, 11645, 11643]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year min: 1950 year max: 2017\n"
     ]
    }
   ],
   "source": [
    "def read_year(year_s):\n",
    "    try:\n",
    "        year = int(year_s)\n",
    "        if year < 0:\n",
    "            year = -year\n",
    "        if year > 2018:\n",
    "            return read_year(year_s[:-1])\n",
    "        else:\n",
    "            return year\n",
    "    except ValueError:\n",
    "        return 1900 + read_year(year_s[:-1])\n",
    "correct_year = sets.year.apply(read_year)\n",
    "print('year min:', correct_year.min(), 'year max:', correct_year.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9   -inf\n",
      "Name: quantity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(inventory_parts.quantity.iloc[[9]]) #comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7670542575540584\n"
     ]
    }
   ],
   "source": [
    "def read_quantity(quantity):\n",
    "    if quantity == float('-inf'):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(quantity)\n",
    "correct_quantity = inventory_parts.quantity.apply(read_quantity)\n",
    "print(correct_quantity.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__\\* Briefly explain your approach here \\*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3. Querying phase\n",
    "Answer the following queries using the functionality of `Pandas`:\n",
    "\n",
    "1. List the ids of the inventories that belong to sets that contain cars. (*Hint: Find a smart way to distinguish which sets contain cars based on the sets' name*).\n",
    "* Plot the distribution of part categories as a (horizontal) bar chart. Restrict yourself to the 20 largest part categories (in terms of the number of parts belonging to the category).\n",
    "* Find the dominant color of each set. Then, plot using a (horizontal) bar chart, the number of sets per dominant color. Color each bar with the respective color that it represents.\n",
    "* Create a scatter plot of the *luminance*\\* of the sets vs their publishing year. What do you observe for the years 1980-1981? How do you interpret what you see?\n",
    "\n",
    "\\*The luminance of a color is a [measure of brightness](https://en.wikipedia.org/wiki/Luminance) which, given its RGB representation, can be computed as follows:\n",
    "\n",
    "$luminance = \\sqrt{0.299*R^2 + 0.587*G^2 + 0.114*B^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168       10187-1\n",
       "229       10248-1\n",
       "792        1306-1\n",
       "793        1307-1\n",
       "1156       1750-1\n",
       "1736       2556-1\n",
       "2054      30190-1\n",
       "2056      30191-1\n",
       "2057      30192-1\n",
       "2058      30193-1\n",
       "2230        306-2\n",
       "2240        307-2\n",
       "2938        390-2\n",
       "2940        391-1\n",
       "2975        395-1\n",
       "3074      40079-1\n",
       "3169      40190-1\n",
       "3171      40191-1\n",
       "3172      40192-1\n",
       "3173      40193-1\n",
       "3245      40252-1\n",
       "3794      42043-1\n",
       "3807      42056-1\n",
       "8327      75870-1\n",
       "8329      75871-1\n",
       "8330      75872-1\n",
       "8331      75873-1\n",
       "8332      75874-1\n",
       "8333      75875-1\n",
       "8334      75876-1\n",
       "           ...   \n",
       "8354      75911-1\n",
       "8355      75912-1\n",
       "8356      75913-1\n",
       "9163       8123-1\n",
       "9185       8142-1\n",
       "9186       8142-2\n",
       "9187       8143-1\n",
       "9188       8144-1\n",
       "9189       8144-2\n",
       "9190       8145-1\n",
       "9199       8153-1\n",
       "9201       8155-1\n",
       "9202       8156-1\n",
       "9203       8157-1\n",
       "9215       8168-1\n",
       "9216       8169-1\n",
       "9221       8185-1\n",
       "9355       8362-1\n",
       "9366       8375-1\n",
       "9376       8386-1\n",
       "9920       8652-1\n",
       "9921       8653-1\n",
       "9922       8654-1\n",
       "9938       8671-1\n",
       "9939       8672-1\n",
       "9940       8673-1\n",
       "9941       8674-1\n",
       "11044    auditt-1\n",
       "11309     K8362-1\n",
       "11337     K8672-1\n",
       "Name: id, Length: 68, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "car_keywords = ['Rolls-Royce' , 'Cadillac' , 'Renault' , 'Ford' , 'Berlinetta' , 'Audi' , 'Chevrolet' , 'Ferrari' , 'Lamborghini' , 'McLaren' , 'Mercedes' , 'Porsche' , 'VW' ]\n",
    "def car(s):\n",
    "    for keyword in car_keywords:\n",
    "        if(keyword in s):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "sets[sets.name.apply(car)].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__\\* Briefly explain your approach for every query here \\*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B. Drop the bike\n",
    "\n",
    "*Los Angeles Metro* has been sharing publicly [anonymized *Metro Bike Share* trip data](https://bikeshare.metro.net/about/data/) under the [Open Database License (ODbL)](http://opendatacommons.org/licenses/odbl/1.0/).\n",
    "\n",
    "In this task you will again perform data wrangling and interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1. Loading phase\n",
    "Load the json file into a `DataFrame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIKES_DATA_FOLDER = DATA_FOLDER + '/bikes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. Cleaning phase\n",
    "Describe the type and the value range of each attribute. Indicate and transform the attributes that are `Categorical`. Are there redundant columns in the dataset (i.e., are there columns whose value depends only on the value of another column)? What are the possible pitfalls of having such columns? Reduce *data redundancy* by extracting such columns to separate `DataFrames`. Which of the two formats (the initial one or the one with reduced data redundancy) is more susceptible to inconsistencies? At the end print for each `Dataframe` the *type of each column* and it's *shape*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__\\* Briefly explain your approach here \\*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3. Querying phase\n",
    "Answer the following queries using the functionality of `Pandas`.\n",
    "\n",
    "1. Plot the *distribution* of the number of outgoing trips from each station in a histogram with 20 bins (Hint: each bin describes a range of counts, not stations).\n",
    "* Plot histograms for the *duration* and *trip starting hour in the day* attributes. For both the *duration*  and the *trip starting hour* use *discrete 1-hour intervals*. What do you observe in each plot? What are some popular values in the *duration* plot? Explain the local maxima and the trends you observe on the *trip starting hour* plot based on human behavior.\n",
    "* For each *trip route category*, calculate the proportion of trips by *passholder type* and present your results in *a stacked bar chart with normalized height*.\n",
    "* Considering only trips that begin in the morning hours (before noon), plot in *a single bar chart* the proportion of trips by *passholder type* and *trip route category*. Explain any outliers you observe.\n",
    "* Separate the hours of the day into two intervals that have (approximately) the same number of bikes leaving the stations. For each of the two intervals calculate the proportion of trips by *passholder type* and *trip route category*. Present your results in a `DataFrame` which has a unique, non-composite index. Does the proportion of trips depend on whether it is the first or second hour interval? Would the company have any significant benefit by creating a more complex paying scheme where monthly pass users would pay less in the first interval and (equally) more on the second one? Assume that the number of trips per interval will not change if the scheme changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__\\* Briefly explain your approach for every query here \\*__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
